{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "faQ6oFF_lHu2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(TN, FP, FN, TP, f_beta=1):\n",
        "    Acc = (TP+TN)/(TN+FP+FN+TP)\n",
        "    P = TP/(TP+FP)\n",
        "    R = TP/(TP+FN)\n",
        "    F = (1+pow(f_beta,2))*(P*R)/((pow(f_beta,2))*P+R)\n",
        "    TNR = TN/(TN+FN)\n",
        "    return Acc, P, R, F, TNR\n",
        "\n",
        "\n",
        "def train_test_split_idxs(correct_col, test_ratio=0.25, balanced=True):\n",
        "    label_0 = list(np.argwhere(correct_col==0)[:,0])\n",
        "    label_1 = list(np.argwhere(correct_col==1)[:,0])\n",
        "\n",
        "    if balanced:\n",
        "        sample_size = min(len(label_0), len(label_1))\n",
        "        label_0 = random.sample(label_0, sample_size)\n",
        "        label_1 = random.sample(label_1, sample_size)\n",
        "    \n",
        "    test_idxs_0 = random.sample(label_0, int(test_ratio*len(label_0)))\n",
        "    test_idxs_1 = random.sample(label_1, int(test_ratio*len(label_1)))\n",
        "    train_idxs_0 = list(set(label_0)-set(test_idxs_0))\n",
        "    train_idxs_1 = list(set(label_1)-set(test_idxs_1))\n",
        "\n",
        "    test_idxs = test_idxs_0 + test_idxs_1\n",
        "    train_idxs = train_idxs_0 + train_idxs_1\n",
        "\n",
        "    random.shuffle(test_idxs)\n",
        "    random.shuffle(train_idxs)\n",
        "\n",
        "    # print(f\"tr_0: {len(train_idxs_0)}\", end=\" \")\n",
        "    # print(f\"tr_1: {len(train_idxs_1)}\", end=\" \")\n",
        "    # print(f\"ts_0: {len(test_idxs_0)}\", end=\" \")\n",
        "    # print(f\"ts_1: {len(test_idxs_1)}\", end=\" \")\n",
        "    # print()\n",
        "\n",
        "    # train_idxs, test_idxs = train_test_split(labels_idxs, test_size=int(test_ratio*len(labels_idxs)))\n",
        "    # test_idxs = random.sample(labels_idxs, int(test_ratio*len(labels_idxs)))\n",
        "    # train_idxs = list(set(labels_idxs)-set(test_idxs))\n",
        "\n",
        "    return train_idxs, test_idxs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'used_language': float,\n",
              " 'specificity': float,\n",
              " 'question_length': float,\n",
              " 'complexity': float,\n",
              " 'image_relatedness': float,\n",
              " 'image_difficulty': float,\n",
              " 'difficulty': float,\n",
              " 'no_tokens': float,\n",
              " 'correct': float,\n",
              " 'N': float,\n",
              " 'Prob': float,\n",
              " 'P_T_1': float,\n",
              " 'P_T_2_N': float}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_names = [\"Vilt\", \"Blip_large\", \"GiT_base\", \"GiT_large\"] # skip , \"Blip_base\"\n",
        "model_type = \"VQA\"\n",
        "D_type = \"1\"\n",
        "\n",
        "full_df_columns = [\"feature\", \"model_name\", \"classifier\", \"TP\", \"TN\", \"FP\", \"FN\", \"Acc\", \"P\", \"R\", \"F\", \"TNR\"]\n",
        "\n",
        "numeric_cols = [\"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\", \"difficulty\", \\\n",
        "                \"no_tokens\", \"correct\", \"N\", \"Prob\", \"P_T_1\", 'P_T_2_N']\n",
        "numeric_cols_dtype = dict()\n",
        "for c in numeric_cols: numeric_cols_dtype[c]=float\n",
        "numeric_cols_dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read full results df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2nL08k6BmCOw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>image_name</th>\n",
              "      <th>example_question</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_gt</th>\n",
              "      <th>used_language</th>\n",
              "      <th>specificity</th>\n",
              "      <th>question_length</th>\n",
              "      <th>complexity</th>\n",
              "      <th>image_relatedness</th>\n",
              "      <th>...</th>\n",
              "      <th>P_T_2_N</th>\n",
              "      <th>x_max_str</th>\n",
              "      <th>x_min_str</th>\n",
              "      <th>Prob_str</th>\n",
              "      <th>T_1_max_str</th>\n",
              "      <th>T_1_str</th>\n",
              "      <th>P_T_1_str</th>\n",
              "      <th>T_2_max_N_str</th>\n",
              "      <th>T_2_N_str</th>\n",
              "      <th>P_T_2_N_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>what is in the image?</td>\n",
              "      <td>what is in the image?</td>\n",
              "      <td>random+noise+nothing+t know+not sure+unknown+c...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035396</td>\n",
              "      <td>-2.3610375</td>\n",
              "      <td>-16.713715</td>\n",
              "      <td>0.07764137</td>\n",
              "      <td>1.7832804974941396</td>\n",
              "      <td>1.3263668739558916</td>\n",
              "      <td>0.033901606</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.307533</td>\n",
              "      <td>0.035396315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>what is the dominant color of the image?</td>\n",
              "      <td>what is the dominant color of the image?</td>\n",
              "      <td>color+gray+grey+nothing+t know+not sure+unknow...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.166710</td>\n",
              "      <td>-0.49326575</td>\n",
              "      <td>-27.210875</td>\n",
              "      <td>0.20900321</td>\n",
              "      <td>3.319589136322892</td>\n",
              "      <td>1.9664954734678717</td>\n",
              "      <td>0.08871711</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.307533</td>\n",
              "      <td>0.16670989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>what does the image represent?</td>\n",
              "      <td>what does the image represent?</td>\n",
              "      <td>random+noise+nothing+t know+not sure+unknown+c...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039332</td>\n",
              "      <td>-2.180196</td>\n",
              "      <td>-17.993324</td>\n",
              "      <td>0.08220834</td>\n",
              "      <td>1.964737514053651</td>\n",
              "      <td>1.4019739641890212</td>\n",
              "      <td>0.031976696</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.307533</td>\n",
              "      <td>0.03933237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>why is the image random?</td>\n",
              "      <td>why is the image random?</td>\n",
              "      <td>random+t know+not sure+unknown+can't tell+none...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.051415</td>\n",
              "      <td>-2.5192337</td>\n",
              "      <td>-19.845095</td>\n",
              "      <td>0.12248334</td>\n",
              "      <td>2.152690347564782</td>\n",
              "      <td>1.4802876448186593</td>\n",
              "      <td>0.034029774</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.307533</td>\n",
              "      <td>0.05141516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>why aren't there any objects in the image?</td>\n",
              "      <td>why aren't there any objects in the image?</td>\n",
              "      <td>random+noise+t know+not sure+unknown+can't tel...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029139</td>\n",
              "      <td>-3.1362438</td>\n",
              "      <td>-18.810205</td>\n",
              "      <td>0.06400901</td>\n",
              "      <td>1.9474464197595112</td>\n",
              "      <td>1.394769341566463</td>\n",
              "      <td>0.024084808</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.307533</td>\n",
              "      <td>0.02913933</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID    image_name                            example_question  \\\n",
              "0   0  Gaussian_5_2                       what is in the image?   \n",
              "1   1  Gaussian_5_2    what is the dominant color of the image?   \n",
              "2   2  Gaussian_5_2              what does the image represent?   \n",
              "3   3  Gaussian_5_2                    why is the image random?   \n",
              "4   4  Gaussian_5_2  why aren't there any objects in the image?   \n",
              "\n",
              "                                     question  \\\n",
              "0                       what is in the image?   \n",
              "1    what is the dominant color of the image?   \n",
              "2              what does the image represent?   \n",
              "3                    why is the image random?   \n",
              "4  why aren't there any objects in the image?   \n",
              "\n",
              "                                           answer_gt  used_language  \\\n",
              "0  random+noise+nothing+t know+not sure+unknown+c...            0.0   \n",
              "1  color+gray+grey+nothing+t know+not sure+unknow...            0.0   \n",
              "2  random+noise+nothing+t know+not sure+unknown+c...            0.0   \n",
              "3  random+t know+not sure+unknown+can't tell+none...            0.0   \n",
              "4  random+noise+t know+not sure+unknown+can't tel...            0.0   \n",
              "\n",
              "   specificity  question_length  complexity  image_relatedness  ...   P_T_2_N  \\\n",
              "0          1.0              0.0         0.0                0.0  ...  0.035396   \n",
              "1          1.0              0.0         0.0                0.0  ...  0.166710   \n",
              "2          1.0              0.0         0.0                0.0  ...  0.039332   \n",
              "3          1.0              0.0         0.0                0.0  ...  0.051415   \n",
              "4          1.0              0.0         0.0                0.0  ...  0.029139   \n",
              "\n",
              "     x_max_str   x_min_str    Prob_str         T_1_max_str  \\\n",
              "0   -2.3610375  -16.713715  0.07764137  1.7832804974941396   \n",
              "1  -0.49326575  -27.210875  0.20900321   3.319589136322892   \n",
              "2    -2.180196  -17.993324  0.08220834   1.964737514053651   \n",
              "3   -2.5192337  -19.845095  0.12248334   2.152690347564782   \n",
              "4   -3.1362438  -18.810205  0.06400901  1.9474464197595112   \n",
              "\n",
              "              T_1_str    P_T_1_str  T_2_max_N_str  T_2_N_str  P_T_2_N_str  \n",
              "0  1.3263668739558916  0.033901606       1.738079   1.307533  0.035396315  \n",
              "1  1.9664954734678717   0.08871711       1.738079   1.307533   0.16670989  \n",
              "2  1.4019739641890212  0.031976696       1.738079   1.307533   0.03933237  \n",
              "3  1.4802876448186593  0.034029774       1.738079   1.307533   0.05141516  \n",
              "4   1.394769341566463  0.024084808       1.738079   1.307533   0.02913933  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_results_df = pd.read_excel(f\"./{model_type}_full_results_D_type_{D_type}.xlsx\", sheet_name=f\"{model_type}_D_type_{D_type}_results\",\n",
        "                                dtype=numeric_cols_dtype)\n",
        "\n",
        "full_results_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Add valid column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14276"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "not_nan = np.array(~(full_results_df['clean_answer']).isna())\n",
        "not_qst_mark = np.array(~(full_results_df['clean_answer'].str.contains('?', na=True, regex=False)))\n",
        "\n",
        "valid = np.where(not_nan & not_qst_mark, 1, 0)\n",
        "\n",
        "data = full_results_df.copy()\n",
        "data[\"valid\"] = valid\n",
        "\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"no_tokens\"] = data[\"no_tokens\"]/np.max(list(data[\"no_tokens\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3334.0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(list(data.loc[data[\"valid\"]==1][\"correct\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train Test indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_idxs = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "correct_col = np.array(data.loc[(data[\"valid\"]==1)][\"correct\"]).astype(np.int32)\n",
        "train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25, balanced=False)\n",
        "\n",
        "models_idxs[\"all\"] = [train_idxs, test_idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    correct_col = np.array(data.loc[(data[\"valid\"]==1) & (data[\"model_name\"]==model_name)][\"correct\"]).astype(np.int32)\n",
        "    train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25, balanced=False)\n",
        "    models_idxs[model_name] = [train_idxs, test_idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: Prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"Prob\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: P_T_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"P_T_1\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"P_T_1\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: P_T_2_N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"P_T_2_N\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"P_T_2_N\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"difficulty\"]\n",
        "models_results = dict()\n",
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: Prob, diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\", \"difficulty\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"Prob_diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: All diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"all_diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: Prob, All diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"Prob_all_diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: with tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\", \"no_tokens\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"w_tokens\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Write results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['preds', 'gt'])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models_all_results[\"w_tokens\"][\"Blip_large\"][\"MLP\"].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_rows = list()\n",
        "for feature, models_results in models_all_results.items():\n",
        "    for model_name in model_names+[\"all\"]:\n",
        "        model_results = models_results[model_name]\n",
        "        for m_name, results in model_results.items():\n",
        "            one_row = list()\n",
        "            TN, FP, FN, TP = confusion_matrix(results[\"gt\"], results[\"preds\"]).ravel()\n",
        "            Acc, P, R, F, TNR = calculate_metrics(TN, FP, FN, TP, f_beta=0.5)\n",
        "            one_row = [feature, model_name, m_name, TP, TN, FP, FN, Acc, P, R, F, TNR]\n",
        "            all_rows.append(one_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>model_name</th>\n",
              "      <th>classifier</th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>Acc</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F</th>\n",
              "      <th>TNR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>16</td>\n",
              "      <td>680</td>\n",
              "      <td>21</td>\n",
              "      <td>174</td>\n",
              "      <td>0.7811447811447811</td>\n",
              "      <td>0.43243243243243246</td>\n",
              "      <td>0.08421052631578947</td>\n",
              "      <td>0.2366863905325444</td>\n",
              "      <td>0.7962529274004684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>MLP</td>\n",
              "      <td>13</td>\n",
              "      <td>682</td>\n",
              "      <td>19</td>\n",
              "      <td>177</td>\n",
              "      <td>0.7800224466891134</td>\n",
              "      <td>0.40625</td>\n",
              "      <td>0.06842105263157895</td>\n",
              "      <td>0.20440251572327048</td>\n",
              "      <td>0.7939464493597206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>25</td>\n",
              "      <td>634</td>\n",
              "      <td>28</td>\n",
              "      <td>204</td>\n",
              "      <td>0.7396184062850729</td>\n",
              "      <td>0.4716981132075472</td>\n",
              "      <td>0.1091703056768559</td>\n",
              "      <td>0.2834467120181406</td>\n",
              "      <td>0.7565632458233891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>MLP</td>\n",
              "      <td>30</td>\n",
              "      <td>632</td>\n",
              "      <td>30</td>\n",
              "      <td>199</td>\n",
              "      <td>0.7429854096520763</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.13100436681222707</td>\n",
              "      <td>0.31982942430703626</td>\n",
              "      <td>0.7605294825511432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Prob</td>\n",
              "      <td>GiT_base</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>50</td>\n",
              "      <td>513</td>\n",
              "      <td>34</td>\n",
              "      <td>183</td>\n",
              "      <td>0.7217948717948718</td>\n",
              "      <td>0.5952380952380952</td>\n",
              "      <td>0.2145922746781116</td>\n",
              "      <td>0.4393673110720562</td>\n",
              "      <td>0.7370689655172413</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  feature  model_name classifier  TP   TN  FP   FN                 Acc  \\\n",
              "0    Prob        Vilt     LogReg  16  680  21  174  0.7811447811447811   \n",
              "1    Prob        Vilt        MLP  13  682  19  177  0.7800224466891134   \n",
              "2    Prob  Blip_large     LogReg  25  634  28  204  0.7396184062850729   \n",
              "3    Prob  Blip_large        MLP  30  632  30  199  0.7429854096520763   \n",
              "4    Prob    GiT_base     LogReg  50  513  34  183  0.7217948717948718   \n",
              "\n",
              "                     P                    R                    F  \\\n",
              "0  0.43243243243243246  0.08421052631578947   0.2366863905325444   \n",
              "1              0.40625  0.06842105263157895  0.20440251572327048   \n",
              "2   0.4716981132075472   0.1091703056768559   0.2834467120181406   \n",
              "3                  0.5  0.13100436681222707  0.31982942430703626   \n",
              "4   0.5952380952380952   0.2145922746781116   0.4393673110720562   \n",
              "\n",
              "                  TNR  \n",
              "0  0.7962529274004684  \n",
              "1  0.7939464493597206  \n",
              "2  0.7565632458233891  \n",
              "3  0.7605294825511432  \n",
              "4  0.7370689655172413  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_df = pd.DataFrame(np.array(all_rows), columns=full_df_columns)\n",
        "full_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = [\"TP\", \"TN\", \"FP\", \"FN\", \"Acc\", \"P\", \"R\", \"F\", \"TNR\"]\n",
        "full_df[num_cols] = full_df[num_cols].apply(pd.to_numeric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>model_name</th>\n",
              "      <th>classifier</th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>Acc</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F</th>\n",
              "      <th>TNR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>16</td>\n",
              "      <td>680</td>\n",
              "      <td>21</td>\n",
              "      <td>174</td>\n",
              "      <td>0.781145</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.084211</td>\n",
              "      <td>0.236686</td>\n",
              "      <td>0.796253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>MLP</td>\n",
              "      <td>13</td>\n",
              "      <td>682</td>\n",
              "      <td>19</td>\n",
              "      <td>177</td>\n",
              "      <td>0.780022</td>\n",
              "      <td>0.406250</td>\n",
              "      <td>0.068421</td>\n",
              "      <td>0.204403</td>\n",
              "      <td>0.793946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>25</td>\n",
              "      <td>634</td>\n",
              "      <td>28</td>\n",
              "      <td>204</td>\n",
              "      <td>0.739618</td>\n",
              "      <td>0.471698</td>\n",
              "      <td>0.109170</td>\n",
              "      <td>0.283447</td>\n",
              "      <td>0.756563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>MLP</td>\n",
              "      <td>30</td>\n",
              "      <td>632</td>\n",
              "      <td>30</td>\n",
              "      <td>199</td>\n",
              "      <td>0.742985</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.131004</td>\n",
              "      <td>0.319829</td>\n",
              "      <td>0.760529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Prob</td>\n",
              "      <td>GiT_base</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>50</td>\n",
              "      <td>513</td>\n",
              "      <td>34</td>\n",
              "      <td>183</td>\n",
              "      <td>0.721795</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.214592</td>\n",
              "      <td>0.439367</td>\n",
              "      <td>0.737069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>GiT_base</td>\n",
              "      <td>MLP</td>\n",
              "      <td>136</td>\n",
              "      <td>523</td>\n",
              "      <td>24</td>\n",
              "      <td>97</td>\n",
              "      <td>0.844872</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.583691</td>\n",
              "      <td>0.778923</td>\n",
              "      <td>0.843548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>GiT_large</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>94</td>\n",
              "      <td>300</td>\n",
              "      <td>38</td>\n",
              "      <td>86</td>\n",
              "      <td>0.760618</td>\n",
              "      <td>0.712121</td>\n",
              "      <td>0.522222</td>\n",
              "      <td>0.663842</td>\n",
              "      <td>0.777202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>GiT_large</td>\n",
              "      <td>MLP</td>\n",
              "      <td>115</td>\n",
              "      <td>309</td>\n",
              "      <td>29</td>\n",
              "      <td>65</td>\n",
              "      <td>0.818533</td>\n",
              "      <td>0.798611</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.760582</td>\n",
              "      <td>0.826203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>all</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>348</td>\n",
              "      <td>2091</td>\n",
              "      <td>159</td>\n",
              "      <td>485</td>\n",
              "      <td>0.791113</td>\n",
              "      <td>0.686391</td>\n",
              "      <td>0.417767</td>\n",
              "      <td>0.608179</td>\n",
              "      <td>0.811724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>all</td>\n",
              "      <td>MLP</td>\n",
              "      <td>463</td>\n",
              "      <td>2127</td>\n",
              "      <td>123</td>\n",
              "      <td>370</td>\n",
              "      <td>0.840091</td>\n",
              "      <td>0.790102</td>\n",
              "      <td>0.555822</td>\n",
              "      <td>0.728675</td>\n",
              "      <td>0.851822</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature  model_name classifier   TP    TN   FP   FN       Acc         P  \\\n",
              "0       Prob        Vilt     LogReg   16   680   21  174  0.781145  0.432432   \n",
              "1       Prob        Vilt        MLP   13   682   19  177  0.780022  0.406250   \n",
              "2       Prob  Blip_large     LogReg   25   634   28  204  0.739618  0.471698   \n",
              "3       Prob  Blip_large        MLP   30   632   30  199  0.742985  0.500000   \n",
              "4       Prob    GiT_base     LogReg   50   513   34  183  0.721795  0.595238   \n",
              "..       ...         ...        ...  ...   ...  ...  ...       ...       ...   \n",
              "75  w_tokens    GiT_base        MLP  136   523   24   97  0.844872  0.850000   \n",
              "76  w_tokens   GiT_large     LogReg   94   300   38   86  0.760618  0.712121   \n",
              "77  w_tokens   GiT_large        MLP  115   309   29   65  0.818533  0.798611   \n",
              "78  w_tokens         all     LogReg  348  2091  159  485  0.791113  0.686391   \n",
              "79  w_tokens         all        MLP  463  2127  123  370  0.840091  0.790102   \n",
              "\n",
              "           R         F       TNR  \n",
              "0   0.084211  0.236686  0.796253  \n",
              "1   0.068421  0.204403  0.793946  \n",
              "2   0.109170  0.283447  0.756563  \n",
              "3   0.131004  0.319829  0.760529  \n",
              "4   0.214592  0.439367  0.737069  \n",
              "..       ...       ...       ...  \n",
              "75  0.583691  0.778923  0.843548  \n",
              "76  0.522222  0.663842  0.777202  \n",
              "77  0.638889  0.760582  0.826203  \n",
              "78  0.417767  0.608179  0.811724  \n",
              "79  0.555822  0.728675  0.851822  \n",
              "\n",
              "[80 rows x 12 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # i = i+1\n",
        "# i = 0\n",
        "# print(i)\n",
        "# with pd.ExcelWriter(f\"./{model_type}_classifier_results_not_balanced.xlsx\", engine=\"openpyxl\", mode=\"w\") as writer:\n",
        "#     full_df.to_excel(writer, sheet_name=f\"{model_type}_classifier_results_{i}\", index_label='ID')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loop!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|â–ˆ         | 1/10 [01:50<16:37, 110.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|â–ˆâ–ˆ        | 2/10 [04:08<16:51, 126.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [06:40<16:08, 138.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [08:42<13:11, 131.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [10:51<10:53, 130.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [12:58<08:38, 129.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [15:06<06:26, 128.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [17:49<04:39, 139.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [20:14<02:21, 141.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [22:44<00:00, 136.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "balanced = False\n",
        "\n",
        "for i in tqdm(range(10)):\n",
        "    # Train Test indices\n",
        "    models_idxs = dict()\n",
        "    ## Full set\n",
        "    correct_col = np.array(data.loc[(data[\"valid\"]==1)][\"correct\"]).astype(np.int32)\n",
        "    train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25, balanced=balanced)\n",
        "\n",
        "    models_idxs[\"all\"] = [train_idxs, test_idxs]\n",
        "    ## Models\n",
        "    for model_name in model_names:\n",
        "        correct_col = np.array(data.loc[(data[\"valid\"]==1) & (data[\"model_name\"]==model_name)][\"correct\"]).astype(np.int32)\n",
        "        train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25, balanced=balanced)\n",
        "        models_idxs[model_name] = [train_idxs, test_idxs]\n",
        "    # Classifiers\n",
        "    models_all_results = dict()\n",
        "    ## Feature: Prob\n",
        "    features = [\"Prob\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"Prob\"] = models_results.copy()\n",
        "    ## Feature: P_T_1\n",
        "    features = [\"P_T_1\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"P_T_1\"] = models_results.copy()\n",
        "    ## Feature: P_T_2_N\n",
        "    features = [\"P_T_2_N\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"P_T_2_N\"] = models_results.copy()\n",
        "    ## Feature: diff\n",
        "    features = [\"difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"diff\"] = models_results.copy()\n",
        "    ## Feature: Prob, diff\n",
        "    features = [\"Prob\", \"difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"Prob_diff\"] = models_results.copy()\n",
        "    ## Feature: All diff\n",
        "    features = [\"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"all_diff\"] = models_results.copy()\n",
        "    ## Feature: Prob, All diff\n",
        "    features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"Prob_all_diff\"] = models_results.copy()\n",
        "    ## Feature: with tokens\n",
        "    features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\", \"no_tokens\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"w_tokens\"] = models_results.copy()\n",
        "    # Write results\n",
        "    all_rows = list()\n",
        "    for feature, models_results in models_all_results.items():\n",
        "        for model_name in model_names+[\"all\"]:\n",
        "            model_results = models_results[model_name]\n",
        "            for m_name, results in model_results.items():\n",
        "                one_row = list()\n",
        "                TN, FP, FN, TP = confusion_matrix(results[\"gt\"], results[\"preds\"]).ravel()\n",
        "                Acc, P, R, F, TNR = calculate_metrics(TN, FP, FN, TP, f_beta=0.5)\n",
        "                one_row = [feature, model_name, m_name, TP, TN, FP, FN, Acc, P, R, F, TNR]\n",
        "                all_rows.append(one_row)\n",
        "    full_df = pd.DataFrame(np.array(all_rows), columns=full_df_columns)\n",
        "    full_df.head()\n",
        "    num_cols = [\"TP\", \"TN\", \"FP\", \"FN\", \"Acc\", \"P\", \"R\", \"F\", \"TNR\"]\n",
        "    full_df[num_cols] = full_df[num_cols].apply(pd.to_numeric)\n",
        "    full_df\n",
        "    try:\n",
        "        with pd.ExcelWriter(f\"./{model_type}_classifier_results_not_balanced.xlsx\", engine=\"openpyxl\", mode=\"a\") as writer:\n",
        "            full_df.to_excel(writer, sheet_name=f\"{model_type}_classifier_results_{i}\", index_label='ID')\n",
        "    except:\n",
        "        with pd.ExcelWriter(f\"./{model_type}_classifier_results_not_balanced.xlsx\", engine=\"openpyxl\", mode=\"w\") as writer:\n",
        "            full_df.to_excel(writer, sheet_name=f\"{model_type}_classifier_results_{i}\", index_label='ID')\n",
        "\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
