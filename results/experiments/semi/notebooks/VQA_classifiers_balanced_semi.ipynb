{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "faQ6oFF_lHu2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(TN, FP, FN, TP, f_beta=1):\n",
        "    Acc = (TP+TN)/(TN+FP+FN+TP)\n",
        "    P = TP/(TP+FP)\n",
        "    R = TP/(TP+FN)\n",
        "    F = (1+pow(f_beta,2))*(P*R)/((pow(f_beta,2))*P+R)\n",
        "    TNR = TN/(TN+FN)\n",
        "    return Acc, P, R, F, TNR\n",
        "\n",
        "def train_test_split_idxs(correct_col, test_ratio=0.25, balanced=True):\n",
        "    label_0 = list(np.argwhere(correct_col==0)[:,0])\n",
        "    label_1 = list(np.argwhere(correct_col==1)[:,0])\n",
        "\n",
        "    if balanced:\n",
        "        sample_size = min(len(label_0), len(label_1))\n",
        "        label_0 = random.sample(label_0, sample_size)\n",
        "        label_1 = random.sample(label_1, sample_size)\n",
        "    \n",
        "    test_idxs_0 = random.sample(label_0, int(test_ratio*len(label_0)))\n",
        "    test_idxs_1 = random.sample(label_1, int(test_ratio*len(label_1)))\n",
        "    train_idxs_0 = list(set(label_0)-set(test_idxs_0))\n",
        "    train_idxs_1 = list(set(label_1)-set(test_idxs_1))\n",
        "\n",
        "    test_idxs = test_idxs_0 + test_idxs_1\n",
        "    train_idxs = train_idxs_0 + train_idxs_1\n",
        "\n",
        "    random.shuffle(test_idxs)\n",
        "    random.shuffle(train_idxs)\n",
        "\n",
        "    # print(f\"tr_0: {len(train_idxs_0)}\", end=\" \")\n",
        "    # print(f\"tr_1: {len(train_idxs_1)}\", end=\" \")\n",
        "    # print(f\"ts_0: {len(test_idxs_0)}\", end=\" \")\n",
        "    # print(f\"ts_1: {len(test_idxs_1)}\", end=\" \")\n",
        "    # print()\n",
        "\n",
        "    # train_idxs, test_idxs = train_test_split(labels_idxs, test_size=int(test_ratio*len(labels_idxs)))\n",
        "    # test_idxs = random.sample(labels_idxs, int(test_ratio*len(labels_idxs)))\n",
        "    # train_idxs = list(set(labels_idxs)-set(test_idxs))\n",
        "\n",
        "    return train_idxs, test_idxs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'used_language': float,\n",
              " 'specificity': float,\n",
              " 'question_length': float,\n",
              " 'complexity': float,\n",
              " 'image_relatedness': float,\n",
              " 'image_difficulty': float,\n",
              " 'difficulty': float,\n",
              " 'no_tokens': float,\n",
              " 'correct': float,\n",
              " 'N': float,\n",
              " 'Prob': float,\n",
              " 'P_T_1': float,\n",
              " 'P_T_2_N': float}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_names = [\"Vilt\", \"Blip_large\", \"GiT_base\", \"GiT_large\"] # skip , \"Blip_base\"\n",
        "model_type = \"VQA\"\n",
        "D_type = \"1\"\n",
        "\n",
        "full_df_columns = [\"feature\", \"model_name\", \"classifier\", \"TP\", \"TN\", \"FP\", \"FN\", \"Acc\", \"P\", \"R\", \"F\", \"TNR\"]\n",
        "\n",
        "numeric_cols = [\"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\", \"difficulty\", \\\n",
        "                \"no_tokens\", \"correct\", \"N\", \"Prob\", \"P_T_1\", 'P_T_2_N']\n",
        "numeric_cols_dtype = dict()\n",
        "for c in numeric_cols: numeric_cols_dtype[c]=float\n",
        "numeric_cols_dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read full results df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2nL08k6BmCOw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>image_name</th>\n",
              "      <th>example_question</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_gt</th>\n",
              "      <th>used_language</th>\n",
              "      <th>specificity</th>\n",
              "      <th>question_length</th>\n",
              "      <th>complexity</th>\n",
              "      <th>image_relatedness</th>\n",
              "      <th>...</th>\n",
              "      <th>P_T_2_N</th>\n",
              "      <th>x_max_str</th>\n",
              "      <th>x_min_str</th>\n",
              "      <th>Prob_str</th>\n",
              "      <th>T_1_max_str</th>\n",
              "      <th>T_1_str</th>\n",
              "      <th>P_T_1_str</th>\n",
              "      <th>T_2_max_N_str</th>\n",
              "      <th>T_2_N_str</th>\n",
              "      <th>P_T_2_N_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>what is in the image?</td>\n",
              "      <td>what is in the image?</td>\n",
              "      <td>random+noise+nothing+t know+not sure+unknown+c...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034218</td>\n",
              "      <td>-2.3610375</td>\n",
              "      <td>-16.713715</td>\n",
              "      <td>0.07764137</td>\n",
              "      <td>1.7832804974941396</td>\n",
              "      <td>1.3420218417625023</td>\n",
              "      <td>0.032721758</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.322284</td>\n",
              "      <td>0.03421847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>what is the dominant color of the image?</td>\n",
              "      <td>what is the dominant color of the image?</td>\n",
              "      <td>color+gray+grey+nothing+t know+not sure+unknow...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.163208</td>\n",
              "      <td>-0.49326575</td>\n",
              "      <td>-27.210875</td>\n",
              "      <td>0.20900321</td>\n",
              "      <td>3.319589136322892</td>\n",
              "      <td>2.055044035268893</td>\n",
              "      <td>0.079705656</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.335708</td>\n",
              "      <td>0.16320807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>what does the image represent?</td>\n",
              "      <td>what does the image represent?</td>\n",
              "      <td>random+noise+nothing+t know+not sure+unknown+c...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038639</td>\n",
              "      <td>-2.180196</td>\n",
              "      <td>-17.993324</td>\n",
              "      <td>0.08220834</td>\n",
              "      <td>1.964737514053651</td>\n",
              "      <td>1.4123228521774975</td>\n",
              "      <td>0.031281423</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.315450</td>\n",
              "      <td>0.03863878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>why is the image random?</td>\n",
              "      <td>why is the image random?</td>\n",
              "      <td>random+t know+not sure+unknown+can't tell+none...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.050391</td>\n",
              "      <td>-2.5192337</td>\n",
              "      <td>-19.845095</td>\n",
              "      <td>0.12248334</td>\n",
              "      <td>2.152690347564782</td>\n",
              "      <td>1.492652731817528</td>\n",
              "      <td>0.03310744</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.315450</td>\n",
              "      <td>0.05039108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>why aren't there any objects in the image?</td>\n",
              "      <td>why aren't there any objects in the image?</td>\n",
              "      <td>random+noise+t know+not sure+unknown+can't tel...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027360</td>\n",
              "      <td>-3.1362438</td>\n",
              "      <td>-18.810205</td>\n",
              "      <td>0.06400901</td>\n",
              "      <td>1.9474464197595112</td>\n",
              "      <td>1.4309373924249116</td>\n",
              "      <td>0.022342704</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.335708</td>\n",
              "      <td>0.027359627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID    image_name                            example_question  \\\n",
              "0   0  Gaussian_5_2                       what is in the image?   \n",
              "1   1  Gaussian_5_2    what is the dominant color of the image?   \n",
              "2   2  Gaussian_5_2              what does the image represent?   \n",
              "3   3  Gaussian_5_2                    why is the image random?   \n",
              "4   4  Gaussian_5_2  why aren't there any objects in the image?   \n",
              "\n",
              "                                     question  \\\n",
              "0                       what is in the image?   \n",
              "1    what is the dominant color of the image?   \n",
              "2              what does the image represent?   \n",
              "3                    why is the image random?   \n",
              "4  why aren't there any objects in the image?   \n",
              "\n",
              "                                           answer_gt  used_language  \\\n",
              "0  random+noise+nothing+t know+not sure+unknown+c...            0.0   \n",
              "1  color+gray+grey+nothing+t know+not sure+unknow...            0.0   \n",
              "2  random+noise+nothing+t know+not sure+unknown+c...            0.0   \n",
              "3  random+t know+not sure+unknown+can't tell+none...            0.0   \n",
              "4  random+noise+t know+not sure+unknown+can't tel...            0.0   \n",
              "\n",
              "   specificity  question_length  complexity  image_relatedness  ...   P_T_2_N  \\\n",
              "0          1.0         0.035714    0.222222                0.0  ...  0.034218   \n",
              "1          1.0         0.142857    0.333333                0.0  ...  0.163208   \n",
              "2          1.0         0.035714    0.111111                0.0  ...  0.038639   \n",
              "3          1.0         0.035714    0.111111                0.0  ...  0.050391   \n",
              "4          1.0         0.142857    0.333333                0.0  ...  0.027360   \n",
              "\n",
              "     x_max_str   x_min_str    Prob_str         T_1_max_str  \\\n",
              "0   -2.3610375  -16.713715  0.07764137  1.7832804974941396   \n",
              "1  -0.49326575  -27.210875  0.20900321   3.319589136322892   \n",
              "2    -2.180196  -17.993324  0.08220834   1.964737514053651   \n",
              "3   -2.5192337  -19.845095  0.12248334   2.152690347564782   \n",
              "4   -3.1362438  -18.810205  0.06400901  1.9474464197595112   \n",
              "\n",
              "              T_1_str    P_T_1_str  T_2_max_N_str  T_2_N_str  P_T_2_N_str  \n",
              "0  1.3420218417625023  0.032721758       1.738079   1.322284   0.03421847  \n",
              "1   2.055044035268893  0.079705656       1.738079   1.335708   0.16320807  \n",
              "2  1.4123228521774975  0.031281423       1.738079   1.315450   0.03863878  \n",
              "3   1.492652731817528   0.03310744       1.738079   1.315450   0.05039108  \n",
              "4  1.4309373924249116  0.022342704       1.738079   1.335708  0.027359627  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_results_df = pd.read_excel(f\"./{model_type}_full_results_D_type_{D_type}_semi.xlsx\", sheet_name=f\"{model_type}_D_type_{D_type}_results\",\n",
        "                                dtype=numeric_cols_dtype)\n",
        "\n",
        "full_results_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Add valid column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14276"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "not_nan = np.array(~(full_results_df['clean_answer']).isna())\n",
        "not_qst_mark = np.array(~(full_results_df['clean_answer'].str.contains('?', na=True, regex=False)))\n",
        "\n",
        "valid = np.where(not_nan & not_qst_mark, 1, 0)\n",
        "\n",
        "data = full_results_df.copy()\n",
        "data[\"valid\"] = valid\n",
        "\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"no_tokens\"] = data[\"no_tokens\"]/np.max(list(data[\"no_tokens\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3334.0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(list(data.loc[data[\"valid\"]==1][\"correct\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train Test indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_idxs = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "correct_col = np.array(data.loc[(data[\"valid\"]==1)][\"correct\"]).astype(np.int32)\n",
        "train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25)\n",
        "\n",
        "models_idxs[\"all\"] = [train_idxs, test_idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vilt\n",
            "Blip_large\n",
            "GiT_base\n",
            "GiT_large\n"
          ]
        }
      ],
      "source": [
        "for model_name in model_names:\n",
        "    print(model_name)\n",
        "    correct_col = np.array(data.loc[(data[\"valid\"]==1) & (data[\"model_name\"]==model_name)][\"correct\"]).astype(np.int32)\n",
        "    train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25)\n",
        "    models_idxs[model_name] = [train_idxs, test_idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: Prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"Prob\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: P_T_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"P_T_1\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"P_T_1\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: P_T_2_N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"P_T_2_N\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"P_T_2_N\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"difficulty\"]\n",
        "models_results = dict()\n",
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: Prob, diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\", \"difficulty\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"Prob_diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: All diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"all_diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: Prob, All diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"Prob_all_diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: with tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\", \"no_tokens\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"w_tokens\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Write results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['preds', 'gt'])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models_all_results[\"w_tokens\"][\"Blip_large\"][\"MLP\"].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_rows = list()\n",
        "for feature, models_results in models_all_results.items():\n",
        "    for model_name in model_names+[\"all\"]:\n",
        "        model_results = models_results[model_name]\n",
        "        for m_name, results in model_results.items():\n",
        "            one_row = list()\n",
        "            TN, FP, FN, TP = confusion_matrix(results[\"gt\"], results[\"preds\"]).ravel()\n",
        "            Acc, P, R, F, TNR = calculate_metrics(TN, FP, FN, TP, f_beta=0.5)\n",
        "            one_row = [feature, model_name, m_name, TP, TN, FP, FN, Acc, P, R, F, TNR]\n",
        "            all_rows.append(one_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>model_name</th>\n",
              "      <th>classifier</th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>Acc</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F</th>\n",
              "      <th>TNR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>102</td>\n",
              "      <td>140</td>\n",
              "      <td>50</td>\n",
              "      <td>88</td>\n",
              "      <td>0.6368421052631579</td>\n",
              "      <td>0.6710526315789473</td>\n",
              "      <td>0.5368421052631579</td>\n",
              "      <td>0.6390977443609022</td>\n",
              "      <td>0.6140350877192983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>MLP</td>\n",
              "      <td>103</td>\n",
              "      <td>140</td>\n",
              "      <td>50</td>\n",
              "      <td>87</td>\n",
              "      <td>0.6394736842105263</td>\n",
              "      <td>0.673202614379085</td>\n",
              "      <td>0.5421052631578948</td>\n",
              "      <td>0.6421446384039902</td>\n",
              "      <td>0.6167400881057269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>125</td>\n",
              "      <td>164</td>\n",
              "      <td>65</td>\n",
              "      <td>104</td>\n",
              "      <td>0.631004366812227</td>\n",
              "      <td>0.6578947368421053</td>\n",
              "      <td>0.5458515283842795</td>\n",
              "      <td>0.6319514661274015</td>\n",
              "      <td>0.6119402985074627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>MLP</td>\n",
              "      <td>126</td>\n",
              "      <td>162</td>\n",
              "      <td>67</td>\n",
              "      <td>103</td>\n",
              "      <td>0.62882096069869</td>\n",
              "      <td>0.6528497409326425</td>\n",
              "      <td>0.5502183406113537</td>\n",
              "      <td>0.6293706293706294</td>\n",
              "      <td>0.6113207547169811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Prob</td>\n",
              "      <td>GiT_base</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>111</td>\n",
              "      <td>176</td>\n",
              "      <td>57</td>\n",
              "      <td>122</td>\n",
              "      <td>0.6158798283261803</td>\n",
              "      <td>0.6607142857142857</td>\n",
              "      <td>0.47639484978540775</td>\n",
              "      <td>0.6132596685082873</td>\n",
              "      <td>0.5906040268456376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  feature  model_name classifier   TP   TN  FP   FN                 Acc  \\\n",
              "0    Prob        Vilt     LogReg  102  140  50   88  0.6368421052631579   \n",
              "1    Prob        Vilt        MLP  103  140  50   87  0.6394736842105263   \n",
              "2    Prob  Blip_large     LogReg  125  164  65  104   0.631004366812227   \n",
              "3    Prob  Blip_large        MLP  126  162  67  103    0.62882096069869   \n",
              "4    Prob    GiT_base     LogReg  111  176  57  122  0.6158798283261803   \n",
              "\n",
              "                    P                    R                   F  \\\n",
              "0  0.6710526315789473   0.5368421052631579  0.6390977443609022   \n",
              "1   0.673202614379085   0.5421052631578948  0.6421446384039902   \n",
              "2  0.6578947368421053   0.5458515283842795  0.6319514661274015   \n",
              "3  0.6528497409326425   0.5502183406113537  0.6293706293706294   \n",
              "4  0.6607142857142857  0.47639484978540775  0.6132596685082873   \n",
              "\n",
              "                  TNR  \n",
              "0  0.6140350877192983  \n",
              "1  0.6167400881057269  \n",
              "2  0.6119402985074627  \n",
              "3  0.6113207547169811  \n",
              "4  0.5906040268456376  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_df = pd.DataFrame(np.array(all_rows), columns=full_df_columns)\n",
        "full_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# num_cols = [\"TP\", \"TN\", \"FP\", \"FN\", \"Acc\", \"P\", \"R\", \"F\", \"TNR\"]\n",
        "# full_df[num_cols] = full_df[num_cols].apply(pd.to_numeric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>model_name</th>\n",
              "      <th>classifier</th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>Acc</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F</th>\n",
              "      <th>TNR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>102</td>\n",
              "      <td>140</td>\n",
              "      <td>50</td>\n",
              "      <td>88</td>\n",
              "      <td>0.6368421052631579</td>\n",
              "      <td>0.6710526315789473</td>\n",
              "      <td>0.5368421052631579</td>\n",
              "      <td>0.6390977443609022</td>\n",
              "      <td>0.6140350877192983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>MLP</td>\n",
              "      <td>103</td>\n",
              "      <td>140</td>\n",
              "      <td>50</td>\n",
              "      <td>87</td>\n",
              "      <td>0.6394736842105263</td>\n",
              "      <td>0.673202614379085</td>\n",
              "      <td>0.5421052631578948</td>\n",
              "      <td>0.6421446384039902</td>\n",
              "      <td>0.6167400881057269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>125</td>\n",
              "      <td>164</td>\n",
              "      <td>65</td>\n",
              "      <td>104</td>\n",
              "      <td>0.631004366812227</td>\n",
              "      <td>0.6578947368421053</td>\n",
              "      <td>0.5458515283842795</td>\n",
              "      <td>0.6319514661274015</td>\n",
              "      <td>0.6119402985074627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>MLP</td>\n",
              "      <td>126</td>\n",
              "      <td>162</td>\n",
              "      <td>67</td>\n",
              "      <td>103</td>\n",
              "      <td>0.62882096069869</td>\n",
              "      <td>0.6528497409326425</td>\n",
              "      <td>0.5502183406113537</td>\n",
              "      <td>0.6293706293706294</td>\n",
              "      <td>0.6113207547169811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Prob</td>\n",
              "      <td>GiT_base</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>111</td>\n",
              "      <td>176</td>\n",
              "      <td>57</td>\n",
              "      <td>122</td>\n",
              "      <td>0.6158798283261803</td>\n",
              "      <td>0.6607142857142857</td>\n",
              "      <td>0.47639484978540775</td>\n",
              "      <td>0.6132596685082873</td>\n",
              "      <td>0.5906040268456376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>GiT_base</td>\n",
              "      <td>MLP</td>\n",
              "      <td>177</td>\n",
              "      <td>189</td>\n",
              "      <td>44</td>\n",
              "      <td>56</td>\n",
              "      <td>0.7854077253218884</td>\n",
              "      <td>0.8009049773755657</td>\n",
              "      <td>0.759656652360515</td>\n",
              "      <td>0.7923008057296329</td>\n",
              "      <td>0.7714285714285715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>GiT_large</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>130</td>\n",
              "      <td>133</td>\n",
              "      <td>47</td>\n",
              "      <td>50</td>\n",
              "      <td>0.7305555555555555</td>\n",
              "      <td>0.7344632768361582</td>\n",
              "      <td>0.7222222222222222</td>\n",
              "      <td>0.7319819819819819</td>\n",
              "      <td>0.726775956284153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>GiT_large</td>\n",
              "      <td>MLP</td>\n",
              "      <td>140</td>\n",
              "      <td>152</td>\n",
              "      <td>28</td>\n",
              "      <td>40</td>\n",
              "      <td>0.8111111111111111</td>\n",
              "      <td>0.8333333333333334</td>\n",
              "      <td>0.7777777777777778</td>\n",
              "      <td>0.8215962441314553</td>\n",
              "      <td>0.7916666666666666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>all</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>589</td>\n",
              "      <td>626</td>\n",
              "      <td>207</td>\n",
              "      <td>244</td>\n",
              "      <td>0.7292917166866747</td>\n",
              "      <td>0.7399497487437185</td>\n",
              "      <td>0.7070828331332533</td>\n",
              "      <td>0.7331341797361215</td>\n",
              "      <td>0.7195402298850575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>all</td>\n",
              "      <td>MLP</td>\n",
              "      <td>645</td>\n",
              "      <td>637</td>\n",
              "      <td>196</td>\n",
              "      <td>188</td>\n",
              "      <td>0.7695078031212484</td>\n",
              "      <td>0.7669441141498217</td>\n",
              "      <td>0.7743097238895558</td>\n",
              "      <td>0.7684060042887778</td>\n",
              "      <td>0.7721212121212121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature  model_name classifier   TP   TN   FP   FN                 Acc  \\\n",
              "0       Prob        Vilt     LogReg  102  140   50   88  0.6368421052631579   \n",
              "1       Prob        Vilt        MLP  103  140   50   87  0.6394736842105263   \n",
              "2       Prob  Blip_large     LogReg  125  164   65  104   0.631004366812227   \n",
              "3       Prob  Blip_large        MLP  126  162   67  103    0.62882096069869   \n",
              "4       Prob    GiT_base     LogReg  111  176   57  122  0.6158798283261803   \n",
              "..       ...         ...        ...  ...  ...  ...  ...                 ...   \n",
              "75  w_tokens    GiT_base        MLP  177  189   44   56  0.7854077253218884   \n",
              "76  w_tokens   GiT_large     LogReg  130  133   47   50  0.7305555555555555   \n",
              "77  w_tokens   GiT_large        MLP  140  152   28   40  0.8111111111111111   \n",
              "78  w_tokens         all     LogReg  589  626  207  244  0.7292917166866747   \n",
              "79  w_tokens         all        MLP  645  637  196  188  0.7695078031212484   \n",
              "\n",
              "                     P                    R                   F  \\\n",
              "0   0.6710526315789473   0.5368421052631579  0.6390977443609022   \n",
              "1    0.673202614379085   0.5421052631578948  0.6421446384039902   \n",
              "2   0.6578947368421053   0.5458515283842795  0.6319514661274015   \n",
              "3   0.6528497409326425   0.5502183406113537  0.6293706293706294   \n",
              "4   0.6607142857142857  0.47639484978540775  0.6132596685082873   \n",
              "..                 ...                  ...                 ...   \n",
              "75  0.8009049773755657    0.759656652360515  0.7923008057296329   \n",
              "76  0.7344632768361582   0.7222222222222222  0.7319819819819819   \n",
              "77  0.8333333333333334   0.7777777777777778  0.8215962441314553   \n",
              "78  0.7399497487437185   0.7070828331332533  0.7331341797361215   \n",
              "79  0.7669441141498217   0.7743097238895558  0.7684060042887778   \n",
              "\n",
              "                   TNR  \n",
              "0   0.6140350877192983  \n",
              "1   0.6167400881057269  \n",
              "2   0.6119402985074627  \n",
              "3   0.6113207547169811  \n",
              "4   0.5906040268456376  \n",
              "..                 ...  \n",
              "75  0.7714285714285715  \n",
              "76   0.726775956284153  \n",
              "77  0.7916666666666666  \n",
              "78  0.7195402298850575  \n",
              "79  0.7721212121212121  \n",
              "\n",
              "[80 rows x 12 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# i = i+1\n",
        "# print(i)\n",
        "# with pd.ExcelWriter(f\"./{model_type}_classifier_results.xlsx\", engine=\"openpyxl\", mode=\"a\") as writer:\n",
        "#     full_df.to_excel(writer, sheet_name=f\"{model_type}_classifier_results_{i}\", index_label='ID')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loop!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "balanced = True\n",
        "\n",
        "i = 0\n",
        "while i<10:\n",
        "    # Train Test indices\n",
        "    models_idxs = dict()\n",
        "    ## Full set\n",
        "    correct_col = np.array(data.loc[(data[\"valid\"]==1)][\"correct\"]).astype(np.int32)\n",
        "    train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25, balanced=balanced)\n",
        "\n",
        "    models_idxs[\"all\"] = [train_idxs, test_idxs]\n",
        "    ## Models\n",
        "    for model_name in model_names:\n",
        "        correct_col = np.array(data.loc[(data[\"valid\"]==1) & (data[\"model_name\"]==model_name)][\"correct\"]).astype(np.int32)\n",
        "        train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25, balanced=balanced)\n",
        "        models_idxs[model_name] = [train_idxs, test_idxs]\n",
        "    # Classifiers\n",
        "    models_all_results = dict()\n",
        "    ## Feature: Prob\n",
        "    features = [\"Prob\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"Prob\"] = models_results.copy()\n",
        "    ######################################################\n",
        "    ## Feature: P_T_1\n",
        "    features = [\"P_T_1\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"P_T_1\"] = models_results.copy()\n",
        "    ## Feature: P_T_2_N\n",
        "    features = [\"P_T_2_N\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"P_T_2_N\"] = models_results.copy()\n",
        "    ######################################################\n",
        "    ## Feature: diff\n",
        "    features = [\"difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"diff\"] = models_results.copy()\n",
        "    ## Feature: Prob, diff\n",
        "    features = [\"Prob\", \"difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"Prob_diff\"] = models_results.copy()\n",
        "    ## Feature: All diff\n",
        "    features = [\"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"all_diff\"] = models_results.copy()\n",
        "    ## Feature: Prob, All diff\n",
        "    features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"Prob_all_diff\"] = models_results.copy()\n",
        "    ## Feature: with tokens\n",
        "    features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\", \"no_tokens\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"w_tokens\"] = models_results.copy()\n",
        "    # Write results\n",
        "    all_rows = list()\n",
        "    for feature, models_results in models_all_results.items():\n",
        "        for model_name in model_names+[\"all\"]:\n",
        "            model_results = models_results[model_name]\n",
        "            for m_name, results in model_results.items():\n",
        "                one_row = list()\n",
        "                TN, FP, FN, TP = confusion_matrix(results[\"gt\"], results[\"preds\"]).ravel()\n",
        "                Acc, P, R, F, TNR = calculate_metrics(TN, FP, FN, TP, f_beta=0.5)\n",
        "                one_row = [feature, model_name, m_name, TP, TN, FP, FN, Acc, P, R, F, TNR]\n",
        "                all_rows.append(one_row)\n",
        "    full_df = pd.DataFrame(np.array(all_rows), columns=full_df_columns)\n",
        "    full_df.head()\n",
        "    num_cols = [\"TP\", \"TN\", \"FP\", \"FN\", \"Acc\", \"P\", \"R\", \"F\", \"TNR\"]\n",
        "    # full_df[num_cols] = full_df[num_cols].replace(\"nan\", 0)\n",
        "    # full_df[num_cols] = full_df[num_cols].fillna(0)\n",
        "    try:\n",
        "        full_df[num_cols] = full_df[num_cols].apply(pd.to_numeric)\n",
        "        try:\n",
        "            with pd.ExcelWriter(f\"./{model_type}_classifier_results_balanced_semi.xlsx\", engine=\"openpyxl\", mode=\"a\") as writer:\n",
        "                full_df.to_excel(writer, sheet_name=f\"{model_type}_classifier_results_{i}\", index_label='ID')\n",
        "        except:\n",
        "            with pd.ExcelWriter(f\"./{model_type}_classifier_results_balanced_semi.xlsx\", engine=\"openpyxl\", mode=\"w\") as writer:\n",
        "                full_df.to_excel(writer, sheet_name=f\"{model_type}_classifier_results_{i}\", index_label='ID')\n",
        "        i += 1\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "transformers",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
