{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "faQ6oFF_lHu2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(TN, FP, FN, TP, f_beta=1):\n",
        "    Acc = (TP+TN)/(TN+FP+FN+TP)\n",
        "    P = TP/(TP+FP)\n",
        "    R = TP/(TP+FN)\n",
        "    F = (1+pow(f_beta,2))*(P*R)/((pow(f_beta,2))*P+R)\n",
        "    TNR = TN/(TN+FN)\n",
        "    return Acc, P, R, F, TNR\n",
        "\n",
        "def train_test_split_idxs(correct_col, test_ratio=0.25, balanced=True):\n",
        "    label_0 = list(np.argwhere(correct_col==0)[:,0])\n",
        "    label_1 = list(np.argwhere(correct_col==1)[:,0])\n",
        "\n",
        "    if balanced:\n",
        "        sample_size = min(len(label_0), len(label_1))\n",
        "        label_0 = random.sample(label_0, sample_size)\n",
        "        label_1 = random.sample(label_1, sample_size)\n",
        "    \n",
        "    test_idxs_0 = random.sample(label_0, int(test_ratio*len(label_0)))\n",
        "    test_idxs_1 = random.sample(label_1, int(test_ratio*len(label_1)))\n",
        "    train_idxs_0 = list(set(label_0)-set(test_idxs_0))\n",
        "    train_idxs_1 = list(set(label_1)-set(test_idxs_1))\n",
        "\n",
        "    test_idxs = test_idxs_0 + test_idxs_1\n",
        "    train_idxs = train_idxs_0 + train_idxs_1\n",
        "\n",
        "    random.shuffle(test_idxs)\n",
        "    random.shuffle(train_idxs)\n",
        "\n",
        "    # print(f\"tr_0: {len(train_idxs_0)}\", end=\" \")\n",
        "    # print(f\"tr_1: {len(train_idxs_1)}\", end=\" \")\n",
        "    # print(f\"ts_0: {len(test_idxs_0)}\", end=\" \")\n",
        "    # print(f\"ts_1: {len(test_idxs_1)}\", end=\" \")\n",
        "    # print()\n",
        "\n",
        "    # train_idxs, test_idxs = train_test_split(labels_idxs, test_size=int(test_ratio*len(labels_idxs)))\n",
        "    # test_idxs = random.sample(labels_idxs, int(test_ratio*len(labels_idxs)))\n",
        "    # train_idxs = list(set(labels_idxs)-set(test_idxs))\n",
        "\n",
        "    return train_idxs, test_idxs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'used_language': float,\n",
              " 'specificity': float,\n",
              " 'question_length': float,\n",
              " 'complexity': float,\n",
              " 'image_relatedness': float,\n",
              " 'image_difficulty': float,\n",
              " 'difficulty': float,\n",
              " 'no_tokens': float,\n",
              " 'correct': float,\n",
              " 'N': float,\n",
              " 'Prob': float,\n",
              " 'P_T_1': float,\n",
              " 'P_T_2_N': float}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_names = [\"Vilt\", \"Blip_large\", \"GiT_base\", \"GiT_large\"] # skip , \"Blip_base\"\n",
        "model_type = \"VQA\"\n",
        "D_type = \"1\"\n",
        "\n",
        "full_df_columns = [\"feature\", \"model_name\", \"classifier\", \"TP\", \"TN\", \"FP\", \"FN\", \"Acc\", \"P\", \"R\", \"F\", \"TNR\"]\n",
        "\n",
        "numeric_cols = [\"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\", \"difficulty\", \\\n",
        "                \"no_tokens\", \"correct\", \"N\", \"Prob\", \"P_T_1\", 'P_T_2_N']\n",
        "numeric_cols_dtype = dict()\n",
        "for c in numeric_cols: numeric_cols_dtype[c]=float\n",
        "numeric_cols_dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read full results df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2nL08k6BmCOw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>image_name</th>\n",
              "      <th>example_question</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_gt</th>\n",
              "      <th>used_language</th>\n",
              "      <th>specificity</th>\n",
              "      <th>question_length</th>\n",
              "      <th>complexity</th>\n",
              "      <th>image_relatedness</th>\n",
              "      <th>...</th>\n",
              "      <th>P_T_2_N</th>\n",
              "      <th>x_max_str</th>\n",
              "      <th>x_min_str</th>\n",
              "      <th>Prob_str</th>\n",
              "      <th>T_1_max_str</th>\n",
              "      <th>T_1_str</th>\n",
              "      <th>P_T_1_str</th>\n",
              "      <th>T_2_max_N_str</th>\n",
              "      <th>T_2_N_str</th>\n",
              "      <th>P_T_2_N_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>what is in the image?</td>\n",
              "      <td>what is in the image?</td>\n",
              "      <td>random+noise+nothing+t know+not sure+unknown+c...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.716642</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023459</td>\n",
              "      <td>-2.3610375</td>\n",
              "      <td>-16.713715</td>\n",
              "      <td>0.07764137</td>\n",
              "      <td>1.7832804974941396</td>\n",
              "      <td>1.5291325316875395</td>\n",
              "      <td>0.022081973</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.498597</td>\n",
              "      <td>0.023458984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>what is the dominant color of the image?</td>\n",
              "      <td>what is the dominant color of the image?</td>\n",
              "      <td>color+gray+grey+nothing+t know+not sure+unknow...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.722859</td>\n",
              "      <td>...</td>\n",
              "      <td>0.141450</td>\n",
              "      <td>-0.49326575</td>\n",
              "      <td>-27.210875</td>\n",
              "      <td>0.20900321</td>\n",
              "      <td>3.319589136322892</td>\n",
              "      <td>2.6139557853339146</td>\n",
              "      <td>0.039211985</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.513551</td>\n",
              "      <td>0.14144981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>what does the image represent?</td>\n",
              "      <td>what does the image represent?</td>\n",
              "      <td>random+noise+nothing+t know+not sure+unknown+c...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.722580</td>\n",
              "      <td>...</td>\n",
              "      <td>0.026472</td>\n",
              "      <td>-2.180196</td>\n",
              "      <td>-17.993324</td>\n",
              "      <td>0.08220834</td>\n",
              "      <td>1.964737514053651</td>\n",
              "      <td>1.6446894485939199</td>\n",
              "      <td>0.019827817</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.493224</td>\n",
              "      <td>0.02647247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>why is the image random?</td>\n",
              "      <td>why is the image random?</td>\n",
              "      <td>random+t know+not sure+unknown+can't tell+none...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.722770</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033062</td>\n",
              "      <td>-2.5192337</td>\n",
              "      <td>-19.845095</td>\n",
              "      <td>0.12248334</td>\n",
              "      <td>2.152690347564782</td>\n",
              "      <td>1.7703628149102884</td>\n",
              "      <td>0.019071277</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.493271</td>\n",
              "      <td>0.03306224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Gaussian_5_2</td>\n",
              "      <td>why aren't there any objects in the image?</td>\n",
              "      <td>why aren't there any objects in the image?</td>\n",
              "      <td>random+noise+t know+not sure+unknown+can't tel...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.720126</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018999</td>\n",
              "      <td>-3.1362438</td>\n",
              "      <td>-18.810205</td>\n",
              "      <td>0.06400901</td>\n",
              "      <td>1.9474464197595112</td>\n",
              "      <td>1.658364383344993</td>\n",
              "      <td>0.014612811</td>\n",
              "      <td>1.738079</td>\n",
              "      <td>1.512878</td>\n",
              "      <td>0.018999284</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID    image_name                            example_question  \\\n",
              "0   0  Gaussian_5_2                       what is in the image?   \n",
              "1   1  Gaussian_5_2    what is the dominant color of the image?   \n",
              "2   2  Gaussian_5_2              what does the image represent?   \n",
              "3   3  Gaussian_5_2                    why is the image random?   \n",
              "4   4  Gaussian_5_2  why aren't there any objects in the image?   \n",
              "\n",
              "                                     question  \\\n",
              "0                       what is in the image?   \n",
              "1    what is the dominant color of the image?   \n",
              "2              what does the image represent?   \n",
              "3                    why is the image random?   \n",
              "4  why aren't there any objects in the image?   \n",
              "\n",
              "                                           answer_gt  used_language  \\\n",
              "0  random+noise+nothing+t know+not sure+unknown+c...            0.0   \n",
              "1  color+gray+grey+nothing+t know+not sure+unknow...            0.0   \n",
              "2  random+noise+nothing+t know+not sure+unknown+c...            0.0   \n",
              "3  random+t know+not sure+unknown+can't tell+none...            0.0   \n",
              "4  random+noise+t know+not sure+unknown+can't tel...            0.0   \n",
              "\n",
              "   specificity  question_length  complexity  image_relatedness  ...   P_T_2_N  \\\n",
              "0          1.0         0.035714    0.222222           0.716642  ...  0.023459   \n",
              "1          1.0         0.142857    0.333333           0.722859  ...  0.141450   \n",
              "2          1.0         0.035714    0.111111           0.722580  ...  0.026472   \n",
              "3          1.0         0.035714    0.111111           0.722770  ...  0.033062   \n",
              "4          1.0         0.142857    0.333333           0.720126  ...  0.018999   \n",
              "\n",
              "     x_max_str   x_min_str    Prob_str         T_1_max_str  \\\n",
              "0   -2.3610375  -16.713715  0.07764137  1.7832804974941396   \n",
              "1  -0.49326575  -27.210875  0.20900321   3.319589136322892   \n",
              "2    -2.180196  -17.993324  0.08220834   1.964737514053651   \n",
              "3   -2.5192337  -19.845095  0.12248334   2.152690347564782   \n",
              "4   -3.1362438  -18.810205  0.06400901  1.9474464197595112   \n",
              "\n",
              "              T_1_str    P_T_1_str  T_2_max_N_str  T_2_N_str  P_T_2_N_str  \n",
              "0  1.5291325316875395  0.022081973       1.738079   1.498597  0.023458984  \n",
              "1  2.6139557853339146  0.039211985       1.738079   1.513551   0.14144981  \n",
              "2  1.6446894485939199  0.019827817       1.738079   1.493224   0.02647247  \n",
              "3  1.7703628149102884  0.019071277       1.738079   1.493271   0.03306224  \n",
              "4   1.658364383344993  0.014612811       1.738079   1.512878  0.018999284  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_results_df = pd.read_excel(f\"./{model_type}_full_results_D_type_{D_type}_automatic.xlsx\", sheet_name=f\"{model_type}_D_type_{D_type}_results\",\n",
        "                                dtype=numeric_cols_dtype)\n",
        "\n",
        "full_results_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Add valid column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14276"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "not_nan = np.array(~(full_results_df['clean_answer']).isna())\n",
        "not_qst_mark = np.array(~(full_results_df['clean_answer'].str.contains('?', na=True, regex=False)))\n",
        "\n",
        "valid = np.where(not_nan & not_qst_mark, 1, 0)\n",
        "\n",
        "data = full_results_df.copy()\n",
        "data[\"valid\"] = valid\n",
        "\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"no_tokens\"] = data[\"no_tokens\"]/np.max(list(data[\"no_tokens\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3334.0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(list(data.loc[data[\"valid\"]==1][\"correct\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train Test indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_idxs = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "correct_col = np.array(data.loc[(data[\"valid\"]==1)][\"correct\"]).astype(np.int32)\n",
        "train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25)\n",
        "\n",
        "models_idxs[\"all\"] = [train_idxs, test_idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vilt\n",
            "Blip_large\n",
            "GiT_base\n",
            "GiT_large\n"
          ]
        }
      ],
      "source": [
        "for model_name in model_names:\n",
        "    print(model_name)\n",
        "    correct_col = np.array(data.loc[(data[\"valid\"]==1) & (data[\"model_name\"]==model_name)][\"correct\"]).astype(np.int32)\n",
        "    train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25)\n",
        "    models_idxs[model_name] = [train_idxs, test_idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: Prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"Prob\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: P_T_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"P_T_1\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"P_T_1\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: P_T_2_N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"P_T_2_N\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"P_T_2_N\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"difficulty\"]\n",
        "models_results = dict()\n",
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: Prob, diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\", \"difficulty\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"Prob_diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: All diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"all_diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: Prob, All diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"Prob_all_diff\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature: with tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\", \"no_tokens\"]\n",
        "models_results = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name in model_names:\n",
        "    \n",
        "    model_dict = dict()\n",
        "\n",
        "    temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict = dict()\n",
        "\n",
        "model_name = \"all\"\n",
        "\n",
        "temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "train_idxs, test_idxs = models_idxs[model_name]\n",
        "X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "for m_name, model in models.items():\n",
        "    model = model()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "models_results[model_name] = model_dict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_all_results[\"w_tokens\"] = models_results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Write results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['preds', 'gt'])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models_all_results[\"w_tokens\"][\"Blip_large\"][\"MLP\"].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_rows = list()\n",
        "for feature, models_results in models_all_results.items():\n",
        "    for model_name in model_names+[\"all\"]:\n",
        "        model_results = models_results[model_name]\n",
        "        for m_name, results in model_results.items():\n",
        "            one_row = list()\n",
        "            TN, FP, FN, TP = confusion_matrix(results[\"gt\"], results[\"preds\"]).ravel()\n",
        "            Acc, P, R, F, TNR = calculate_metrics(TN, FP, FN, TP, f_beta=0.5)\n",
        "            one_row = [feature, model_name, m_name, TP, TN, FP, FN, Acc, P, R, F, TNR]\n",
        "            all_rows.append(one_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>model_name</th>\n",
              "      <th>classifier</th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>Acc</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F</th>\n",
              "      <th>TNR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>108</td>\n",
              "      <td>144</td>\n",
              "      <td>46</td>\n",
              "      <td>82</td>\n",
              "      <td>0.6631578947368421</td>\n",
              "      <td>0.7012987012987013</td>\n",
              "      <td>0.5684210526315789</td>\n",
              "      <td>0.6699751861042184</td>\n",
              "      <td>0.6371681415929203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>MLP</td>\n",
              "      <td>108</td>\n",
              "      <td>144</td>\n",
              "      <td>46</td>\n",
              "      <td>82</td>\n",
              "      <td>0.6631578947368421</td>\n",
              "      <td>0.7012987012987013</td>\n",
              "      <td>0.5684210526315789</td>\n",
              "      <td>0.6699751861042184</td>\n",
              "      <td>0.6371681415929203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>120</td>\n",
              "      <td>176</td>\n",
              "      <td>53</td>\n",
              "      <td>109</td>\n",
              "      <td>0.6462882096069869</td>\n",
              "      <td>0.6936416184971098</td>\n",
              "      <td>0.5240174672489083</td>\n",
              "      <td>0.6514657980456027</td>\n",
              "      <td>0.6175438596491228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>MLP</td>\n",
              "      <td>124</td>\n",
              "      <td>169</td>\n",
              "      <td>60</td>\n",
              "      <td>105</td>\n",
              "      <td>0.6397379912663755</td>\n",
              "      <td>0.6739130434782609</td>\n",
              "      <td>0.5414847161572053</td>\n",
              "      <td>0.6424870466321244</td>\n",
              "      <td>0.6167883211678832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Prob</td>\n",
              "      <td>GiT_base</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>124</td>\n",
              "      <td>165</td>\n",
              "      <td>68</td>\n",
              "      <td>109</td>\n",
              "      <td>0.6201716738197425</td>\n",
              "      <td>0.6458333333333334</td>\n",
              "      <td>0.5321888412017167</td>\n",
              "      <td>0.6193806193806193</td>\n",
              "      <td>0.6021897810218978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  feature  model_name classifier   TP   TN  FP   FN                 Acc  \\\n",
              "0    Prob        Vilt     LogReg  108  144  46   82  0.6631578947368421   \n",
              "1    Prob        Vilt        MLP  108  144  46   82  0.6631578947368421   \n",
              "2    Prob  Blip_large     LogReg  120  176  53  109  0.6462882096069869   \n",
              "3    Prob  Blip_large        MLP  124  169  60  105  0.6397379912663755   \n",
              "4    Prob    GiT_base     LogReg  124  165  68  109  0.6201716738197425   \n",
              "\n",
              "                    P                   R                   F  \\\n",
              "0  0.7012987012987013  0.5684210526315789  0.6699751861042184   \n",
              "1  0.7012987012987013  0.5684210526315789  0.6699751861042184   \n",
              "2  0.6936416184971098  0.5240174672489083  0.6514657980456027   \n",
              "3  0.6739130434782609  0.5414847161572053  0.6424870466321244   \n",
              "4  0.6458333333333334  0.5321888412017167  0.6193806193806193   \n",
              "\n",
              "                  TNR  \n",
              "0  0.6371681415929203  \n",
              "1  0.6371681415929203  \n",
              "2  0.6175438596491228  \n",
              "3  0.6167883211678832  \n",
              "4  0.6021897810218978  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_df = pd.DataFrame(np.array(all_rows), columns=full_df_columns)\n",
        "full_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# num_cols = [\"TP\", \"TN\", \"FP\", \"FN\", \"Acc\", \"P\", \"R\", \"F\", \"TNR\"]\n",
        "# full_df[num_cols] = full_df[num_cols].apply(pd.to_numeric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>model_name</th>\n",
              "      <th>classifier</th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>Acc</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F</th>\n",
              "      <th>TNR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>108</td>\n",
              "      <td>144</td>\n",
              "      <td>46</td>\n",
              "      <td>82</td>\n",
              "      <td>0.6631578947368421</td>\n",
              "      <td>0.7012987012987013</td>\n",
              "      <td>0.5684210526315789</td>\n",
              "      <td>0.6699751861042184</td>\n",
              "      <td>0.6371681415929203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Vilt</td>\n",
              "      <td>MLP</td>\n",
              "      <td>108</td>\n",
              "      <td>144</td>\n",
              "      <td>46</td>\n",
              "      <td>82</td>\n",
              "      <td>0.6631578947368421</td>\n",
              "      <td>0.7012987012987013</td>\n",
              "      <td>0.5684210526315789</td>\n",
              "      <td>0.6699751861042184</td>\n",
              "      <td>0.6371681415929203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>120</td>\n",
              "      <td>176</td>\n",
              "      <td>53</td>\n",
              "      <td>109</td>\n",
              "      <td>0.6462882096069869</td>\n",
              "      <td>0.6936416184971098</td>\n",
              "      <td>0.5240174672489083</td>\n",
              "      <td>0.6514657980456027</td>\n",
              "      <td>0.6175438596491228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prob</td>\n",
              "      <td>Blip_large</td>\n",
              "      <td>MLP</td>\n",
              "      <td>124</td>\n",
              "      <td>169</td>\n",
              "      <td>60</td>\n",
              "      <td>105</td>\n",
              "      <td>0.6397379912663755</td>\n",
              "      <td>0.6739130434782609</td>\n",
              "      <td>0.5414847161572053</td>\n",
              "      <td>0.6424870466321244</td>\n",
              "      <td>0.6167883211678832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Prob</td>\n",
              "      <td>GiT_base</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>124</td>\n",
              "      <td>165</td>\n",
              "      <td>68</td>\n",
              "      <td>109</td>\n",
              "      <td>0.6201716738197425</td>\n",
              "      <td>0.6458333333333334</td>\n",
              "      <td>0.5321888412017167</td>\n",
              "      <td>0.6193806193806193</td>\n",
              "      <td>0.6021897810218978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>GiT_base</td>\n",
              "      <td>MLP</td>\n",
              "      <td>156</td>\n",
              "      <td>159</td>\n",
              "      <td>74</td>\n",
              "      <td>77</td>\n",
              "      <td>0.6759656652360515</td>\n",
              "      <td>0.6782608695652174</td>\n",
              "      <td>0.6695278969957081</td>\n",
              "      <td>0.676496097137901</td>\n",
              "      <td>0.673728813559322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>GiT_large</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>105</td>\n",
              "      <td>119</td>\n",
              "      <td>61</td>\n",
              "      <td>75</td>\n",
              "      <td>0.6222222222222222</td>\n",
              "      <td>0.6325301204819277</td>\n",
              "      <td>0.5833333333333334</td>\n",
              "      <td>0.6220379146919431</td>\n",
              "      <td>0.6134020618556701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>GiT_large</td>\n",
              "      <td>MLP</td>\n",
              "      <td>112</td>\n",
              "      <td>130</td>\n",
              "      <td>50</td>\n",
              "      <td>68</td>\n",
              "      <td>0.6722222222222223</td>\n",
              "      <td>0.691358024691358</td>\n",
              "      <td>0.6222222222222222</td>\n",
              "      <td>0.6763285024154588</td>\n",
              "      <td>0.6565656565656566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>all</td>\n",
              "      <td>LogReg</td>\n",
              "      <td>554</td>\n",
              "      <td>539</td>\n",
              "      <td>294</td>\n",
              "      <td>279</td>\n",
              "      <td>0.656062424969988</td>\n",
              "      <td>0.6533018867924528</td>\n",
              "      <td>0.6650660264105642</td>\n",
              "      <td>0.6556213017751479</td>\n",
              "      <td>0.6589242053789731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>w_tokens</td>\n",
              "      <td>all</td>\n",
              "      <td>MLP</td>\n",
              "      <td>541</td>\n",
              "      <td>594</td>\n",
              "      <td>239</td>\n",
              "      <td>292</td>\n",
              "      <td>0.6812725090036015</td>\n",
              "      <td>0.6935897435897436</td>\n",
              "      <td>0.6494597839135654</td>\n",
              "      <td>0.6842904123450544</td>\n",
              "      <td>0.6704288939051919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature  model_name classifier   TP   TN   FP   FN                 Acc  \\\n",
              "0       Prob        Vilt     LogReg  108  144   46   82  0.6631578947368421   \n",
              "1       Prob        Vilt        MLP  108  144   46   82  0.6631578947368421   \n",
              "2       Prob  Blip_large     LogReg  120  176   53  109  0.6462882096069869   \n",
              "3       Prob  Blip_large        MLP  124  169   60  105  0.6397379912663755   \n",
              "4       Prob    GiT_base     LogReg  124  165   68  109  0.6201716738197425   \n",
              "..       ...         ...        ...  ...  ...  ...  ...                 ...   \n",
              "75  w_tokens    GiT_base        MLP  156  159   74   77  0.6759656652360515   \n",
              "76  w_tokens   GiT_large     LogReg  105  119   61   75  0.6222222222222222   \n",
              "77  w_tokens   GiT_large        MLP  112  130   50   68  0.6722222222222223   \n",
              "78  w_tokens         all     LogReg  554  539  294  279   0.656062424969988   \n",
              "79  w_tokens         all        MLP  541  594  239  292  0.6812725090036015   \n",
              "\n",
              "                     P                   R                   F  \\\n",
              "0   0.7012987012987013  0.5684210526315789  0.6699751861042184   \n",
              "1   0.7012987012987013  0.5684210526315789  0.6699751861042184   \n",
              "2   0.6936416184971098  0.5240174672489083  0.6514657980456027   \n",
              "3   0.6739130434782609  0.5414847161572053  0.6424870466321244   \n",
              "4   0.6458333333333334  0.5321888412017167  0.6193806193806193   \n",
              "..                 ...                 ...                 ...   \n",
              "75  0.6782608695652174  0.6695278969957081   0.676496097137901   \n",
              "76  0.6325301204819277  0.5833333333333334  0.6220379146919431   \n",
              "77   0.691358024691358  0.6222222222222222  0.6763285024154588   \n",
              "78  0.6533018867924528  0.6650660264105642  0.6556213017751479   \n",
              "79  0.6935897435897436  0.6494597839135654  0.6842904123450544   \n",
              "\n",
              "                   TNR  \n",
              "0   0.6371681415929203  \n",
              "1   0.6371681415929203  \n",
              "2   0.6175438596491228  \n",
              "3   0.6167883211678832  \n",
              "4   0.6021897810218978  \n",
              "..                 ...  \n",
              "75   0.673728813559322  \n",
              "76  0.6134020618556701  \n",
              "77  0.6565656565656566  \n",
              "78  0.6589242053789731  \n",
              "79  0.6704288939051919  \n",
              "\n",
              "[80 rows x 12 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# i = i+1\n",
        "# print(i)\n",
        "# with pd.ExcelWriter(f\"./{model_type}_classifier_results.xlsx\", engine=\"openpyxl\", mode=\"a\") as writer:\n",
        "#     full_df.to_excel(writer, sheet_name=f\"{model_type}_classifier_results_{i}\", index_label='ID')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loop!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "balanced = True\n",
        "\n",
        "i = 0\n",
        "while i<10:\n",
        "    # Train Test indices\n",
        "    models_idxs = dict()\n",
        "    ## Full set\n",
        "    correct_col = np.array(data.loc[(data[\"valid\"]==1)][\"correct\"]).astype(np.int32)\n",
        "    train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25, balanced=balanced)\n",
        "\n",
        "    models_idxs[\"all\"] = [train_idxs, test_idxs]\n",
        "    ## Models\n",
        "    for model_name in model_names:\n",
        "        correct_col = np.array(data.loc[(data[\"valid\"]==1) & (data[\"model_name\"]==model_name)][\"correct\"]).astype(np.int32)\n",
        "        train_idxs, test_idxs = train_test_split_idxs(correct_col, test_ratio=0.25, balanced=balanced)\n",
        "        models_idxs[model_name] = [train_idxs, test_idxs]\n",
        "    # Classifiers\n",
        "    models_all_results = dict()\n",
        "    ## Feature: Prob\n",
        "    features = [\"Prob\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"Prob\"] = models_results.copy()\n",
        "    ######################################################\n",
        "    ## Feature: P_T_1\n",
        "    features = [\"P_T_1\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"P_T_1\"] = models_results.copy()\n",
        "    ## Feature: P_T_2_N\n",
        "    features = [\"P_T_2_N\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"P_T_2_N\"] = models_results.copy()\n",
        "    ######################################################\n",
        "    ## Feature: diff\n",
        "    features = [\"difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"diff\"] = models_results.copy()\n",
        "    ## Feature: Prob, diff\n",
        "    features = [\"Prob\", \"difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"Prob_diff\"] = models_results.copy()\n",
        "    ## Feature: All diff\n",
        "    features = [\"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"all_diff\"] = models_results.copy()\n",
        "    ## Feature: Prob, All diff\n",
        "    features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"Prob_all_diff\"] = models_results.copy()\n",
        "    ## Feature: with tokens\n",
        "    features = [\"Prob\", \"used_language\", \"specificity\", \"question_length\", \"complexity\", \"image_relatedness\", \"image_difficulty\", \"no_tokens\"]\n",
        "    models_results = dict()\n",
        "    for model_name in model_names:\n",
        "        \n",
        "        model_dict = dict()\n",
        "\n",
        "        temp = data.loc[(data[\"model_name\"]==model_name) & (data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "        train_idxs, test_idxs = models_idxs[model_name]\n",
        "        X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "        y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "        models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "        for m_name, model in models.items():\n",
        "            model = model()\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "            model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "        models_results[model_name] = model_dict.copy()\n",
        "\n",
        "    model_dict = dict()\n",
        "\n",
        "    model_name = \"all\"\n",
        "\n",
        "    temp = data.loc[(data[\"valid\"]==1)] #  & (data['image_difficulty']!=2)\n",
        "\n",
        "    train_idxs, test_idxs = models_idxs[model_name]\n",
        "    X_train, X_test = np.array(temp[features])[train_idxs], np.array(temp[features])[test_idxs]\n",
        "    y_train, y_test = np.array(temp[\"correct\"])[train_idxs], np.array(temp[\"correct\"])[test_idxs]\n",
        "\n",
        "    models = {\"LogReg\": LogisticRegression, \"MLP\":MLPClassifier}\n",
        "\n",
        "    for m_name, model in models.items():\n",
        "        model = model()\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test)\n",
        "        model_dict[m_name]={\"preds\":predictions, \"gt\":y_test}\n",
        "\n",
        "    models_results[model_name] = model_dict.copy()\n",
        "    models_all_results[\"w_tokens\"] = models_results.copy()\n",
        "    # Write results\n",
        "    all_rows = list()\n",
        "    for feature, models_results in models_all_results.items():\n",
        "        for model_name in model_names+[\"all\"]:\n",
        "            model_results = models_results[model_name]\n",
        "            for m_name, results in model_results.items():\n",
        "                one_row = list()\n",
        "                TN, FP, FN, TP = confusion_matrix(results[\"gt\"], results[\"preds\"]).ravel()\n",
        "                Acc, P, R, F, TNR = calculate_metrics(TN, FP, FN, TP, f_beta=0.5)\n",
        "                one_row = [feature, model_name, m_name, TP, TN, FP, FN, Acc, P, R, F, TNR]\n",
        "                all_rows.append(one_row)\n",
        "    full_df = pd.DataFrame(np.array(all_rows), columns=full_df_columns)\n",
        "    full_df.head()\n",
        "    num_cols = [\"TP\", \"TN\", \"FP\", \"FN\", \"Acc\", \"P\", \"R\", \"F\", \"TNR\"]\n",
        "    # full_df[num_cols] = full_df[num_cols].replace(\"nan\", 0)\n",
        "    # full_df[num_cols] = full_df[num_cols].fillna(0)\n",
        "    try:\n",
        "        full_df[num_cols] = full_df[num_cols].apply(pd.to_numeric)\n",
        "        try:\n",
        "            with pd.ExcelWriter(f\"./{model_type}_classifier_results_balanced_automatic.xlsx\", engine=\"openpyxl\", mode=\"a\") as writer:\n",
        "                full_df.to_excel(writer, sheet_name=f\"{model_type}_classifier_results_{i}\", index_label='ID')\n",
        "        except:\n",
        "            with pd.ExcelWriter(f\"./{model_type}_classifier_results_balanced_automatic.xlsx\", engine=\"openpyxl\", mode=\"w\") as writer:\n",
        "                full_df.to_excel(writer, sheet_name=f\"{model_type}_classifier_results_{i}\", index_label='ID')\n",
        "        i += 1\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "transformers",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
